{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Defect Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In this chapter, we learn about the concept of defect prediction. The basic idea is to determine the probability for a release/commit to be buggy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###  Defect Prediction\n",
    "\n",
    "![Defect Prediction Overview](figures/General-framework-of-Just-in-Time-JIT-defect-prediction.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "figure taken from Fan, Xia, Costa, Lo, Hassan, Li \\\n",
    "The Impact of Mislabeled Changes by SZZ on Just-in-Time Defect Prediction \\\n",
    "TSE, 2019\n",
    "\n",
    "https://www.researchgate.net/figure/General-framework-of-Just-in-Time-JIT-defect-prediction_fig1_334553555"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Defect prediction is done on different levels of abstraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Just-In-Time (JIT) vs. Release-level\n",
    "* commit level vs. release level prediction\n",
    "* change-based or process-based metrics vs. metrics from static analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Metrics\n",
    "\n",
    "![Defect Prediction Overview](figures/framework_defect_prediction_metrics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Types\n",
    "\n",
    "* change-related *(ch)*\n",
    "* process-related *(pr)*\n",
    "* static code analysis metrics like\n",
    "  - Chidamber and Kemerer 1994, \"A metrics suite for object oriented design\" *(ck)*\n",
    "  - additional object-oriented metrics *(oo)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### JIT Defect Prediction\n",
    "\n",
    "| Metric      | Description | Type |\n",
    "|--|:-|--|\n",
    "| NS      | The number of modified subsystems | ch |\n",
    "| ND      | The number of modified directories | ch |\n",
    "| NF      | The number of modified files | ch |\n",
    "| Entropy | Distribution of modified code across each file | ch |\n",
    "| LA      | Lines of code added | ch |\n",
    "| LD      | Lines of code deleted | ch |\n",
    "| LT      | Lines of code in a file before the change | ch |\n",
    "| FIX     | Whether or not the change is a defect fix | ch |\n",
    "| NDEV    | The number of developers that changed the modified files | pr |\n",
    "| AGE     | The average time interval between the last and current change | pr |\n",
    "| NUC     | The number of unique changes to the modified files | pr |\n",
    "| EXP     | Developer experience | pr |\n",
    "| REXP    | Recent developer experience | pr |\n",
    "| SEXP    | Developer experience on a subsystem | pr |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "metrics + description taken from \\\n",
    "Zeng, Zhengran / Zhang, Yuqun / Zhang, Haotian / Zhang, Lingming \\\n",
    "Deep just-in-time defect prediction: how far are we? \\\n",
    "ISSTA 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Release-level Defect Prediction\n",
    "similar to metrics used in the domain of static analysis\n",
    "\n",
    "| Name | Description | Type |\n",
    "| -- | :- | -- |\n",
    "| WMC    | Weighted method count | ck |\n",
    "| DIT    | Depth of inheritance tree | ck |\n",
    "| RFC    | Response for class | ck |\n",
    "| NOC    | Number of children | ck |\n",
    "| CBO    | Coupling between objects | ck |\n",
    "| LCOM   | Lack of cohesion in methods | ck |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Release-level Defect Prediction\n",
    "similar to metrics used in the domain of static analysis\n",
    "\n",
    "| Name | Description | Type |\n",
    "| -- | :- | -- |\n",
    "| FanIn  | Number of other classes that reference the class | oo |\n",
    "| FanOut | Number of other classes referenced by the class | oo |\n",
    "| NOA    | Number of attributes | oo |\n",
    "| NOPA   | Number of public attributes | oo |\n",
    "| NOPRA  | Number of private attributes | oo |\n",
    "| NOAI   | Number of attributes inherited | oo |\n",
    "| LOC    | Number of lines of code | oo |\n",
    "| NOM    | Number of methods | oo |\n",
    "| NOPM   | Number of public methods | oo |\n",
    "| NOPRM  | Number of private methods | oo |\n",
    "| NOMI  | Number of methods inherited | oo |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "table taken from \\\n",
    "D’Ambros, Lanza, Robbes \\\n",
    "Evaluating defect prediction approaches: a benchmark and an extensive comparison  \\\n",
    "Empirical Software Engineering 2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Metrics are not necessarily used strictly for release-level or JIT defect prediction.\n",
    "There are also approaches to use, for example, the second type of metrics also for JIT defect prediction [Trautsch, Herbold, Grabowski, 2020].\n",
    "\n",
    "Modern deep learning approaches do not require manual feature engineering at all [Hoang, Kang, Lo, Lawall, 2020]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training Data\n",
    "\n",
    "![Defect Prediction Overview](figures/framework_defect_prediction_within_cross.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Within- vs. Cross-Project Defect Prediction\n",
    "\n",
    "![Within- vs. Cross-Project Defect Prediction](figures/Within-project-and-cross-project-defect-prediction-scenario-Nam-etal-2017.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "figure taken from \\\n",
    "Marjuni, Adji, Ferdiana \\\n",
    "Unsupervised software defect prediction using signed Laplacian-based spectral classifier \\\n",
    "Soft Computing 2019\n",
    "\n",
    "https://www.researchgate.net/figure/Within-project-and-cross-project-defect-prediction-scenario-Nam-etal-2017_fig1_331914573"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### SZZ\n",
    "\n",
    "![Defect Prediction Overview](figures/framework_defect_prediction_szz.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![SZZ Algorithm](figures/szz.ppm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "figure taken from\n",
    "Borg, Svensson, Berg, Hansson  \n",
    "SZZ Unleashed: An Open Implementation of the SZZ Algorithm - Featuring Example Usage in a Study of Just-in-Time Bug Prediction for the Jenkins Project  \n",
    "MaLTeSQuE@ESEC/SIGSOFT FSE 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Recent work has shown that \"only about half of the commits SZZ identifies are actually bug fixing and SZZ misses about one fifth of all bug fixing commits\" [Herbold2022]. Different reasons for this phenomenon may be\n",
    "\n",
    "- tickets (issues) are not necessarily labeled correctly (might be an improvement, but labeled as bug)\n",
    "- not every link from ticket (issue) to bugfix (commit) is valid (number referenced in bugfix might be ticket number, or just any other common number)\n",
    "- not all of the commit identified as introducing is actually causing the bug (whitespace changes, documentation,...)\n",
    "- not every bug is introduced by the code that is needed to change for fixing it\n",
    "- difference between \"intrinsic\" and \"extrinsic\" bugs (extrinsic bugs are introduced by changing requirements, external libraries,... They don't have an explicit introducing commit in the production code)\n",
    "- ...\n",
    "\n",
    "In practice, this means that manual labelling would be neccessary to really improve the training data, which is expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The following data/experiment is based on the replication package of \\\n",
    "Zeng, Zhengran / Zhang, Yuqun / Zhang, Haotian / Zhang, Lingming \\\n",
    "Deep just-in-time defect prediction: how far are we? \\\n",
    "ISSTA 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dataset Example\n",
    "\n",
    "| # | commit id | date | bug | ns | nd | nf | entropy | la | ld | lt | fix | ndev | age | nuc | exp | rexp | sexp\n",
    "| -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- |\n",
    "|0  | \t8951b6... | 1420046511 | 0 | 1 | 1 | 1 | 0 | 2 | 2 | 1098 | 0 | 57 | 12.7706828703704 | 211 | 307 | 15.5851634074379 | 105\n",
    "|1 | \t645d9e... | 1420144596 | 0 | 1 | 1 | 1 | 0 | 3 | 2 | 565 | 0 | 15 | 28.3037847222222 | 58 | 18788 | 706.767646617412 | 2607\n",
    "|2 | \t032619... | 1420144601 | 0 | 1 | 1 | 1 | 0 | 1 | 2 | 238 | 0 | 11 | 132.599097222222 | 20 | 18789 | 707.767417719642 | 2607\n",
    "|3 | \t05b5f4... | 1420144604 | 1 | 1 | 3 | 5 | 1.56733029467246 | 16 | 20 | 3652 | 0 | 35 | 26.9964768518519 | 654 | 18794 | 712.767245665074 | 2607\n",
    "|4 | \t9a2701... | 1420144608 | 0 | 1 | 2 | 3 | 1.14883485428092 | 27 | 29 | 1234 | 0 | 23 | 65.0161458333333 | 161 | 18797 | 715.76678479794 | 2607\n",
    "|5 | \tcb3f52... | 1420192546 | 0 | 1 | 1 | 4 | 1.06742926490304 | 251 | 4 | 5839 | 0  | 16 | 241.4490625 | 50 | 1472 | 61.3856478692205 | 266\n",
    "|6 | \t5dd202... | 1420197074 | 0 | 1 | 1 | 2 | 0.543564443199596 | 7 | 1 | 513 | 0 | 18 | 37.5173784722222 | 55 | 1441 | 9.22531625838597 | 74\n",
    "|7 | \t26b0ff... | 1420201148 | 0 | 1 | 1 | 1 | 0 | 1 | 1 | 177 | 0 | 90 | 39.8427083333333 | 295 | 17581 | 967.320548243851 | 1249\n",
    "|8 | \t21b379... | 1420204547 | 0 | 1 | 1 | 1 | 0 | 0 | 16 | 525 | 1 | 13 | 133.284166666667 | 15 | 773 | 79.7507648398479 | 444\n",
    "|9 | \tcd407e... | 1420207090 | 0 | 1 | 1 | 1 | 0 | 1 | 1 | 122 | 0 | 6 | 134.004722222222 | 7 | 5287 | 496.189183456316 | 1546 |\n",
    "| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/qt_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def drop_all_features_but_la(df):\n",
    "    df = df.replace({True: 1, False: 0})\n",
    "    df = df.fillna(df.mean(numeric_only=True))\n",
    "    df = df[['Unnamed: 0','_id','date','bug','__'] + ['la']]\n",
    "    return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = drop_all_features_but_la(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_ids(data):\n",
    "    # return the labels of data\n",
    "    return data[:, 1:2].flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_label(data):\n",
    "    data = data[:, 3:4].flatten().tolist()\n",
    "    data = [1 if int(d) > 0 else 0 for d in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_features(data):\n",
    "    # return the features of data\n",
    "    return data[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(path_data):\n",
    "    data = pd.read_csv(path_data)\n",
    "    data = drop_all_features_but_la(df=data)\n",
    "    ids, labels, features = get_ids(data=data), get_label(data=data), get_features(data=data)\n",
    "    indexes = list()\n",
    "    cnt_noexits = 0\n",
    "    for i in range(0, len(ids)):\n",
    "        try:\n",
    "            indexes.append(i)\n",
    "        except FileNotFoundError:\n",
    "            print('File commit id no exits', ids[i], cnt_noexits)\n",
    "            cnt_noexits += 1\n",
    "    ids = [ids[i] for i in indexes]\n",
    "    labels = [labels[i] for i in indexes]\n",
    "    features = features[indexes]\n",
    "    return (ids, np.array(labels), features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# import qt dataset (80:20% split)\n",
    "train, test = load_data(\"data/qt_train.csv\"), load_data(\"data/qt_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Here, we use within-project defect prediction (with `train` and `test` dataset both from `qt` project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model\n",
    "\n",
    "![Defect Prediction Overview](figures/framework_defect_prediction_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Examples\n",
    "\n",
    "* Logistic Regression with manual feature engineering\n",
    "* Deep Learning for (semi-) automated feature detection\n",
    "  - Deep Belief Networks\n",
    "  - CC2VEC with distributed vector representation based on vectors for added/removed code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# LApredict: logistic regression with LA (lines added) as metric\n",
    "def defect_prediction_model(train, test, algorithm):\n",
    "    _, Y_train, X_train = train\n",
    "    _, Y_test,  X_test = test\n",
    "    X_train, X_test = preprocessing.scale(X_train), preprocessing.scale(X_test)\n",
    "    \n",
    "    model = LogisticRegression(max_iter=7000).fit(X_train, Y_train)\n",
    "    \n",
    "    Y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    return Y_test, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# train LApredict on (previously imported) qt dataset\n",
    "labels, predicts = defect_prediction_model(train, test, 'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, auc\n",
    "\n",
    "def evaluation_metrics(y_true, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true=y_true, y_score=y_pred, pos_label=1)\n",
    "    auc_ = auc(fpr, tpr)\n",
    "\n",
    "    y_pred = [1 if p >= 0.5 else 0 for p in y_pred]\n",
    "    acc = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    prc = precision_score(y_true=y_true, y_pred=y_pred)\n",
    "    rc = recall_score(y_true=y_true, y_pred=y_pred)\n",
    "    f1 = 0\n",
    "    if (prc + rc) != 0:\n",
    "        f1 = 2 * prc * rc / (prc + rc)\n",
    "    return acc, prc, rc, f1, auc_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "acc, prc, rc, f1, auc_ = evaluation_metrics(y_true=labels, y_pred=predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "auc_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "cross prediction would work the same, just load\n",
    "\n",
    "`train, test = load_data(\"data/cross/qt_train.csv\"), load_data(\"data/cross/qt_test.csv\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "AUC (area under the curve) is a common metric for defect prediction performance.\n",
    "\"[It is ...] not as impacted by highly imbalanced data.\n",
    "AUC is defined as the area under the Receiver Operating Characteristic (ROC) curve which is a plot of the false positive rate, against the true positive rate.\n",
    "AUC values range from 0 to 1 with 0.5 being equivalent to random guessing and 1 being the perfect value with no false positives and every positive correctly identified.\"\n",
    "\n",
    "(Trautsch et al., \"Static source code metrics and static analysis warnings for fine-grained jist-in-time defect prediction\", ICSME 2020)\n",
    "\n",
    "Grafically spoken this means: if the ROC is equal (or close to) a stright line from the bottom left to the top right corner, the classification is equivalent to random guessing.\n",
    "Ideally, the shape of the ROC curve goes from the bottom left to the top right corner, with a sharp curve in the top left corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "RocCurveDisplay.from_predictions(labels, predicts, name=\"Logistic Regression (LA)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# more detailed plot with comparison\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr_la , tpr_la, _ = roc_curve(labels, predicts)\n",
    "auc = round(metrics.roc_auc_score(labels, predicts), 4)\n",
    "\n",
    "random_probs = [0 for _ in range(len(labels))]\n",
    "random_auc = round(metrics.roc_auc_score(labels, random_probs), 4)\n",
    "fpr_rand , tpr_rand, _ = roc_curve(labels, random_probs)\n",
    "\n",
    "plt.plot(fpr_la, tpr_la, label=\"Logistic Regression (LA), AUC=\" + str(auc))\n",
    "plt.plot(fpr_rand, tpr_rand, label=\"Random Classifier, AUC=\" + str(random_auc))\n",
    "plt.legend()\n",
    "plt.xlabel(\"false positive rate (FPR)\")\n",
    "plt.ylabel(\"true positive rate (TPR)\")\n",
    "plt.title('Receiver Operating Characteristic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Performance of different defect prediction algorithms](figures/table8_how_far_are_we.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"accuracy: {acc:.2f}, precision: {prc:.2f}, recall: {rc:.2f}, f1: {f1:.2f}, auc: {auc_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Considering recall (= 0.0, with AUC being 0.74), we can see why this metric alone has problems: if there are close to no positive cases (= commits with bugs), i.e. the data is highly unbalanced, suggesting no defects at all will yield a low false positive rate, thus yield relatively high AUC values while not performing any real defect prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "_, y_train, _ = train\n",
    "\n",
    "# Ratio of positive class in training data\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "print(\"classes: \" + str(unique))\n",
    "print(\"counts: \" + str(counts))\n",
    "\n",
    "print(\"That is only \" + str(round(counts[1] / (counts[0] + counts[1]), 4) * 100) + \"% positive cases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Therefore, the model learns to (almost) only predict the negative class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Actual ratio of positive class for test data\n",
    "\n",
    "print(Counter(labels))\n",
    "print(\"actual ratio positive class: \" + str(round(((Counter(labels)[1] / labels.size) * 100), 2)) + \"% positive cases.\")\n",
    "\n",
    "# Predicted ratio of positive class for test data\n",
    "\n",
    "predicts_bin_class = [1 if p >= 0.5 else 0 for p in predicts]\n",
    "\n",
    "print(Counter(predicts_bin_class))\n",
    "print(\"predicted ratio positive class: \" + str(round(((Counter(predicts_bin_class)[1] / labels.size) * 100), 2)) + \"% positive cases.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Predicted probabilities for test data\n",
    "plt.hist(predicts, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Another representation that may be more suitable for unbalanced datasets is precision/recall tradeoff, since precision/recall focusses on the minority class. The baseline for this representation is a horizontal line from the left to the right at hight `pos/all`, so a classifier that would always predict the positive case for all the data. Ideally, the plot would be a curve from the top left to somwhere in the middle on the right (not worse than baseline at `pos/all`), with a sharp curve in the top right corner.\n",
    "Let's see how this looks for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
    "\n",
    "def precision_recall(y_true, y_pred):\n",
    "    disp = PrecisionRecallDisplay.from_predictions(y_true, y_pred)\n",
    "    plt.axhline(y=(Counter(labels)[1] / labels.size), color='orange', linestyle='-', label=\"baseline\")\n",
    "    plt.title(\"Precision-Recall-Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "precision_recall(labels, predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "| Threshold | tp | fp | fn | Precision | Recall |\n",
    "| --     | -- | -- | -- | -- | -- |\n",
    "| ..     | .. | .. | .. | .. | .. |\n",
    "| 0.5    | 3 | 6 | 692 | 0.3333 | 0.0043 |\n",
    "| ..     | .. | .. | .. | .. | .. |\n",
    "| 0.7438 | 2 | 3 | 693 | 0.4 | 0.0028 |\n",
    "| 0.8634 | 2 | 2 | 693 | 0.5 | 0.0028 |\n",
    "| 0.9576 | 1 | 2 | 694 | 0.3333 | 0.0014 |\n",
    "| 0.9982 | 0 | 2 | 695 | 0 | 0 |\n",
    "| 1      | 0 | 0 | 695 | NaN | 0 |"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
